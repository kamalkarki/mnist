{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tf_exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kamalkarki/mnist/blob/master/Tf_exercise.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6JWjhqesCkPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sn1TukxoFfvL",
        "colab_type": "code",
        "outputId": "80d73210-ca60-4d13-bcc8-ee7710e8d949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  mnist_download = fetch_mldata('MNIST original')\n",
        "  mnist_data = {} # dictionay for dataset\n",
        "  X_train, X_test, y_train, y_test = train_test_split( mnist_download.data, mnist_download.target, test_size=0.20, random_state=42)\n",
        "  print('Data for the mnist data has been downloaded and split into Train and Test data with size:')\n",
        "  print('X_train shape' + str(X_train.shape))\n",
        "  print('y_train shape' + str(y_train.shape))\n",
        "  print('y_test shape' + str(y_test.shape))\n",
        "  print('X_test shape' + str(X_test.shape))\n",
        "  mnist_data['X_train'] = X_train\n",
        "  mnist_data['X_test'] = X_test\n",
        "  mnist_data['y_train'] = y_train\n",
        "  mnist_data['y_test'] = y_test\n",
        "  return mnist_data\n",
        "  \n",
        "mnist_data = get_data()  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for the mnist data has been downloaded and split into Train and Test data with size:\n",
            "X_train shape(56000, 784)\n",
            "y_train shape(56000,)\n",
            "y_test shape(14000,)\n",
            "X_test shape(14000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eb8BZ10IH-Dm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshaping(data):\n",
        "  # reshaping X\n",
        "  #X_train = np.reshape(X_train,(X_train.shape[0],28,28))\n",
        "  #X_test = np.reshape(X_test,(X_test.shape[0],28 ,28))\n",
        "  # reshaping the y\n",
        "  data['y_train'] = np.reshape(data['y_train'],(data['y_train'].shape[0],-1))\n",
        "  data['y_test'] = np.reshape(data['y_test'],(data['y_test'].shape[0],-1))\n",
        "  return data\n",
        "mnist_data = reshaping(mnist_data)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MJxj6DOMNWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def hot_encoding(data):\n",
        "  # 1. INSTANTIATE\n",
        "  enc = OneHotEncoder()\n",
        "  # 2. FIT\n",
        "  enc.fit(data)\n",
        "  # 3. Transform\n",
        "  onehotlabels = enc.transform(data).toarray()\n",
        "  #onehotlabels.shape\n",
        "  return onehotlabels\n",
        "\n",
        "mnist_data['y_train'] = hot_encoding(mnist_data['y_train'])\n",
        "mnist_data['y_test'] = hot_encoding(mnist_data['y_test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "muo5aJeOXMxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# making the graph\n",
        "height = 28\n",
        "width = 28\n",
        "channels = 1\n",
        "n_inputs = height * width\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.name_scope(\"inputs\"):\n",
        "  X = tf.placeholder(tf.float32, shape=[None, height * width], name=\"X\")\n",
        "  X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
        "  y = tf.placeholder(tf.int32, shape=[None,10], name=\"y\")\n",
        "\n",
        "#layer 1  \n",
        "conv1 = tf.layers.conv2d(X_reshaped, filters= 12, kernel_size= 3,\n",
        "                         strides=1, padding=\"SAME\",\n",
        "                         activation=tf.nn.relu, name=\"conv1\")\n",
        "\n",
        "\n",
        "  \n",
        "#layer 2  \n",
        "conv2 = tf.layers.conv2d(conv1, filters = 12, kernel_size = 3,\n",
        "                         strides= 1, padding = \"SAME\",\n",
        "                         activation=tf.nn.relu, name=\"conv2\")\n",
        "\n",
        "with tf.name_scope(\"pool1\"):\n",
        "  #pooling\n",
        "  pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
        "  \n",
        "\n",
        "\n",
        "with tf.name_scope(\"fc1\"):\n",
        "  #flat\n",
        "  flat = tf.contrib.layers.flatten(pool1)\n",
        "  #fully connected\n",
        "  fc = tf.contrib.layers.fully_connected(flat, 64, activation_fn=None)\n",
        "  fc1_drop = tf.layers.dropout(fc,0.5)\n",
        "  \n",
        "with tf.name_scope(\"fc2\"):\n",
        "  #fully connected 2\n",
        "  fc = tf.contrib.layers.fully_connected(flat, 10, activation_fn=None)  \n",
        "\n",
        "# prediction and loss calculation in the same scope\n",
        "with tf.name_scope(\"training\"):\n",
        "  xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=fc, labels= y)\n",
        "  loss = tf.reduce_mean(xentropy)\n",
        "  optimizer = tf.train.AdamOptimizer()\n",
        "  training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "  #correct = tf.nn.in_top_k(logits, y, 1)\n",
        "  #accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "  # Calculate the correct predictions\n",
        "  predict_op = tf.argmax(fc, 1)\n",
        "  correct_prediction = tf.equal(predict_op, tf.argmax(y, 1))\n",
        "\n",
        "  # Calculate accuracy on the test set\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  \n",
        "def fetch_batch(epoch, batch_index, batch_size,data):\n",
        "    np.random.seed(epoch * n_batches + batch_index)  \n",
        "    indices = np.random.randint(m, size=batch_size)  \n",
        "    X_train = data['X_train']\n",
        "    y_train = data['y_train']\n",
        "    X_batch = X_train[indices] \n",
        "    y_batch = y_train[indices] \n",
        "    return X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xb9HsfJUZKtW",
        "colab_type": "code",
        "outputId": "53ef0bb5-25b4-4529-817e-d26a548b0e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "#session = tf.Session(config=config, ...)\n",
        "!mkdir('/model')\n",
        "n_epochs = 50\n",
        "batch_size = 1000\n",
        "m = mnist_data['X_train'].shape[0]\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "save = tf.train.Saver()\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "  init.run()\n",
        "  for epoch in range(0,n_epochs):\n",
        "    for batch_index in range(0,n_batches):\n",
        "      X_train,y_train = fetch_batch(epoch, batch_index, batch_size,mnist_data)\n",
        "      sess.run(training_op, feed_dict={X: X_train, y: y_train})\n",
        "    if epoch % 5 == 0:  \n",
        "      acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
        "      acc_test = accuracy.eval(feed_dict={X: mnist_data['X_test'], y: mnist_data['y_test']})\n",
        "      print(\"Epoch number:\",epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "      \n",
        "  save.save(sess,'model/cnn_1.ckpt')    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `'/model''\n",
            "/bin/bash: -c: line 0: `mkdir('/model')'\n",
            "Epoch number: 0 Train accuracy: 0.909 Test accuracy: 0.8974286\n",
            "Epoch number: 5 Train accuracy: 0.977 Test accuracy: 0.963\n",
            "Epoch number: 10 Train accuracy: 0.989 Test accuracy: 0.97314286\n",
            "Epoch number: 15 Train accuracy: 0.995 Test accuracy: 0.97585714\n",
            "Epoch number: 20 Train accuracy: 0.998 Test accuracy: 0.97814286\n",
            "Epoch number: 25 Train accuracy: 0.999 Test accuracy: 0.9767143\n",
            "Epoch number: 30 Train accuracy: 1.0 Test accuracy: 0.97742856\n",
            "Epoch number: 35 Train accuracy: 1.0 Test accuracy: 0.9779286\n",
            "Epoch number: 40 Train accuracy: 1.0 Test accuracy: 0.9785714\n",
            "Epoch number: 45 Train accuracy: 1.0 Test accuracy: 0.97814286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VrRW5c1s3qsw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ]
    },
    {
      "metadata": {
        "id": "0FeQEj5A3pIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}